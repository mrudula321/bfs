{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classification using Deep neural network:Binary classification using Deep Neural Networks Example: Classify movie reviews into positive\" reviews and \"negative\" reviews, just based on the text content of the reviews.Use IMDB dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required libaries\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the IMDB dataset\n",
    "(x_train,y_train),(x_test,y_test) = imdb.load_data(num_words=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the data\n",
    "maxlen = 256\n",
    "x_train = keras.preprocessing.sequence.pad_sequences(x_train,maxlen = maxlen)\n",
    "x_test =  keras.preprocessing.sequence.pad_sequences(x_test,maxlen = maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Embedding(10000,16,input_length = maxlen),\n",
    "    keras.layers.GlobalAveragePooling1D(),\n",
    "    keras.layers.Dense(16,activation='relu'),\n",
    "    keras.layers.Dense(1,activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(loss = 'binary_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "782/782 [==============================] - 7s 7ms/step - loss: 0.5042 - accuracy: 0.7818 - val_loss: 0.3261 - val_accuracy: 0.8703\n",
      "Epoch 2/30\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.2627 - accuracy: 0.8988 - val_loss: 0.2829 - val_accuracy: 0.8855\n",
      "Epoch 3/30\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.2077 - accuracy: 0.9227 - val_loss: 0.2854 - val_accuracy: 0.8833\n",
      "Epoch 4/30\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.1744 - accuracy: 0.9371 - val_loss: 0.2918 - val_accuracy: 0.8826\n",
      "Epoch 5/30\n",
      "782/782 [==============================] - 6s 8ms/step - loss: 0.1502 - accuracy: 0.9465 - val_loss: 0.3130 - val_accuracy: 0.8766\n",
      "Epoch 6/30\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.1313 - accuracy: 0.9544 - val_loss: 0.3327 - val_accuracy: 0.8746\n",
      "Epoch 7/30\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.1157 - accuracy: 0.9623 - val_loss: 0.3580 - val_accuracy: 0.8699\n",
      "Epoch 8/30\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.1023 - accuracy: 0.9670 - val_loss: 0.3872 - val_accuracy: 0.8670\n",
      "Epoch 9/30\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.0893 - accuracy: 0.9726 - val_loss: 0.4233 - val_accuracy: 0.8638\n",
      "Epoch 10/30\n",
      "782/782 [==============================] - 6s 8ms/step - loss: 0.0792 - accuracy: 0.9771 - val_loss: 0.4559 - val_accuracy: 0.8600\n",
      "Epoch 11/30\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.0706 - accuracy: 0.9798 - val_loss: 0.4959 - val_accuracy: 0.8546\n",
      "Epoch 12/30\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.0617 - accuracy: 0.9831 - val_loss: 0.5327 - val_accuracy: 0.8532\n",
      "Epoch 13/30\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.0536 - accuracy: 0.9859 - val_loss: 0.5817 - val_accuracy: 0.8508\n",
      "Epoch 14/30\n",
      "782/782 [==============================] - 6s 8ms/step - loss: 0.0477 - accuracy: 0.9877 - val_loss: 0.6098 - val_accuracy: 0.8502\n",
      "Epoch 15/30\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.0415 - accuracy: 0.9899 - val_loss: 0.6717 - val_accuracy: 0.8474\n",
      "Epoch 16/30\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.0362 - accuracy: 0.9914 - val_loss: 0.7097 - val_accuracy: 0.8430\n",
      "Epoch 17/30\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.0323 - accuracy: 0.9930 - val_loss: 0.7497 - val_accuracy: 0.8435\n",
      "Epoch 18/30\n",
      "782/782 [==============================] - 6s 8ms/step - loss: 0.0275 - accuracy: 0.9943 - val_loss: 0.8193 - val_accuracy: 0.8412\n",
      "Epoch 19/30\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.0238 - accuracy: 0.9950 - val_loss: 0.8652 - val_accuracy: 0.8405\n",
      "Epoch 20/30\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.0209 - accuracy: 0.9952 - val_loss: 0.9206 - val_accuracy: 0.8359\n",
      "Epoch 21/30\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.0177 - accuracy: 0.9964 - val_loss: 0.9796 - val_accuracy: 0.8359\n",
      "Epoch 22/30\n",
      "782/782 [==============================] - 6s 8ms/step - loss: 0.0148 - accuracy: 0.9965 - val_loss: 1.0311 - val_accuracy: 0.8351\n",
      "Epoch 23/30\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.0127 - accuracy: 0.9975 - val_loss: 1.1032 - val_accuracy: 0.8354\n",
      "Epoch 24/30\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.0107 - accuracy: 0.9980 - val_loss: 1.1420 - val_accuracy: 0.8344\n",
      "Epoch 25/30\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.0098 - accuracy: 0.9982 - val_loss: 1.1978 - val_accuracy: 0.8352\n",
      "Epoch 26/30\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.0083 - accuracy: 0.9982 - val_loss: 1.2379 - val_accuracy: 0.8343\n",
      "Epoch 27/30\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.0081 - accuracy: 0.9983 - val_loss: 1.3546 - val_accuracy: 0.8325\n",
      "Epoch 28/30\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.0080 - accuracy: 0.9983 - val_loss: 1.4220 - val_accuracy: 0.8319\n",
      "Epoch 29/30\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.0051 - accuracy: 0.9992 - val_loss: 1.3978 - val_accuracy: 0.8336\n",
      "Epoch 30/30\n",
      "782/782 [==============================] - 6s 8ms/step - loss: 0.0043 - accuracy: 0.9992 - val_loss: 1.4759 - val_accuracy: 0.8340\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(x_train,y_train,epochs = 30,batch_size = 32,validation_data = (x_test,y_test),verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 2s 2ms/step - loss: 1.4759 - accuracy: 0.8340\n",
      "Test Loss:  1.4758515357971191\n",
      "Test Accuracy:  0.8339999914169312\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Model\n",
    "test_loss,test_acc = model.evaluate(x_test,y_test)\n",
    "print('Test Loss: ',test_loss)\n",
    "print('Test Accuracy: ',test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define new text data to make predictions on\n",
    "\n",
    "tk = Tokenizer()\n",
    "test_data = ['This movie is really great!','This movie is really bad!']\n",
    "\n",
    "tk.fit_on_texts(test_data)\n",
    "\n",
    "sequences = tk.texts_to_sequences(test_data)\n",
    "\n",
    "tdata =  keras.preprocessing.sequence.pad_sequences(sequences,maxlen=maxlen)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 25ms/step\n",
      "[[0.90910995]\n",
      " [0.8616002 ]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Make predictions on the new text data\n",
    "predictions = model.predict(tdata)\n",
    "\n",
    "print(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This movie is really great!  ->  Positive\n",
      "This movie is really bad!  ->  Negative\n"
     ]
    }
   ],
   "source": [
    "# Set the threshold value and classify the input text\n",
    "\n",
    "threshold = 0.87\n",
    "\n",
    "for i in range(len(test_data)):\n",
    "    sentiment = 'Positive' if predictions[i] > threshold else 'Negative'\n",
    "    print(test_data[i],' -> ',sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
